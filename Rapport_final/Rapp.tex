\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[final]{pdfpages} 
\usepackage[french]{babel}
\usepackage{amsmath}
\usepackage[bookmarks={true},bookmarksopen={true}]{hyperref}
\usepackage{graphicx}
\usepackage[a4paper]{geometry}
\usepackage{listings}
	\lstset{frame=tb,
		language=Java,
 		aboveskip=3mm,
  		belowskip=3mm,
  		showstringspaces=false,
  		columns=flexible,
  		basicstyle={\small\ttfamily},
  		numbers=none,
 		numberstyle=\tiny\color{gray},
  		keywordstyle=\color{blue},
  		commentstyle=\color{dkgreen},
  		stringstyle=\color{mauve},
  		breaklines=true,
  		breakatwhitespace=true
  		tabsize=3
	}
\pagestyle{plain}
\setlength{\parindent}{5mm}

\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}



\title{\textbf{Projet LSINF1121 -  Algorithmique et structures de données\\ - \\ Rapport final Mission 5} \\ {\large Groupe 3.2}}
\author{Boris \bsc{Dehem} \\(5586-12-00)\and Sundeep \bsc{Dhillon} \\(6401-11-00)\and Alexandre \bsc{Hauet} \\ (5336-08-00) \and Jonathan \bsc{Powell}\\(6133-12-00)\and Mathieu \bsc{Rosar} \\ (4718-12-00)\and Tanguy \bsc{Vaessen} \\ (0810-14-00)}
\date{date}
\date{\vspace*{25mm}
\includegraphics[scale=0.75]{logo.jpg}\\
		\vspace*{30mm}
		\begin{center}
		Année académique 2014-2015 \\	
		\end{center}}

\begin{document}
\thispagestyle{empty}

\maketitle
\thispagestyle{empty}
%\tableofcontents
\setcounter{tocdepth}{3}

\newpage
\setcounter{page}{1}

\section*{Introduction}

Dans le cadre du cours "Algorithmique et structures de données", il nous a été demandé de concevoir et d'implémenter une application permettant de compresser et décompresser des fichier textuelles sans perte d'information suivant l'algorithme de Huffman. Ainsi un code de longueur variable est attribué à chaque lettre du texte permettant d'avoir un codage en moyenne plus court que le fichier original. Ce programme contient une classe \verb+Compress.Java+ et \verb+Decompress.java+ qui prennent deux arguments un fichier à compresser/à décompresser et en deuxième argument le nom du fichier résultat.

\section{Implémentation}
Pour plus de facilité nous avons choisi que notre programme contiendrait deux \verb+Main+ différentes, une pour la compression et l'autre pour la décompression. Le programme Compress prendra en premier argument un fichier de type TXT et retournera un fichier compressé de format HUF.
Inversement, Decompress prendra un fichier compressé de format HUF et retournera un fichier TXT.

La classe \verb+HuffmanBTRee+ nous permet de créer un arbre selon l'algorithme de Huffman avec une queue de priorité implémentée par la classe \verb+PriorityQueue+ provenant de l'API Java.

Pour la compression, on parcoure le fichier lettre par lettre et pour chaque lettre rencontrée on la map dans une \verb+HasMap+ associé à sa fréquence qui sera incrémentée à chaque fois que la lettre est de nouveau rencontrée.

Ensuite, un \verb+HuffmanTree+ est créé par lettre associé à sa fréquence et stocké en fonction de la valeur de celle-ci dans une file de priorité.

Grâce à la fonction mergeAll de la classe \verb+HuffmanBTRee+ on va créer notre arbre final de Hufman correspondant au fichier qu'on souhaite compressé.

Cet arbre sera mis sous forme binaire, chaque nœud correspondra à un 0 et chaque feuille à un 1 suivi de la valeur du caractère en bits. Il sera ensuite incorporé au début du fichier compresser afin de pouvoir le décompresser plus tard.



\section{Diagramme UML de classe}
Voir question 8 des questions liées au problème posé.

\section{Questions liées au problème posé}

\subsection*{Question 7}
En quoi les deux classes qui vous sont fournies, \textbf{InputBitStream} et OutputBitStream, peuvent-elles être utiles pour le problème de compression et de décompression avec un codage de Huffman ?
La postcondition de la méthode close dans la classe \textbf{OutputBitStream} précise notamment que \textit{si le nombre de bits déjà écrits ne correspond pas à un multiple de 8 (un octet), des bits à 0 sont écrits pour compléter l’octet couran}t. Quand la situation décrite peut-elle se présenter ? Quelle est la conséquence de cette postcondition sur votre programme de compression de texte ? Quelle est la conséquence de cette postcondition sur votre programme de décompression ? \\


Une des particularités du codage de Huffman est qu'il n'utilise pas un nombre de bits constant pour encoder un caractère. Pour chaque fichier différent, l'arbre de Huffman le sera aussi. Grâce aux classes \verb+InputBitStream+ et \verb+OutputBitStream+ les caractères pourront être encodés et lu bit par bit sans avoir à connaître leur taille à l'avance.

Cependant, l'encodage étant en \verb+ASCII+ ou \verb+Unicode+ représenté sur 16 bits, lors de la fermeture du stream tout octet courant entamé devra être complété tant que le nombre de bits du fichier n'est pas un multiple de 8.

Heureusement la classe \verb+OutputBitStream+ avec sa méthode close() permet de faire cela. La post-condition de cette méthode nous assure que lors de la fermeture du fichier si un octet n'est pas complètement écrit, il sera complété par des zéros.

Il faudra donc faire attention lors de la décompression du fichier de ne pas interpréter ces zéros supplémentaires comme des bits représentants des lettres alors qu'en réalité ils ne représentent rien. En résumé, il faut éviter l'erreur d'ajouter au fichier original des lettres supplémentaires.

\subsection*{Question 8}
Donnez un diagramme dé-taillé des différentes classes et interfaces utilisées pour résoudre le problème de compression et de décompression de données. Précisez dans ce diagramme, les liens du type \textit{uses}, \textit{implements} ou \textit{extends}. Quelles sont les classes qui sont communes entre les programmes de compression et de décompression de données ? \\

\subsection*{Question 9}
Quel est le taux de compression observé sur différents fichiers de texte ? Ce taux de compression dépend-il de la taille du fichier ? Y a-t-il d'autres paramètres qui influencent ce taux de compression ? Décrivez précisément les différents essais que vous aurez effectués avec vos programmes de compression et de décompression de texte. Quel est le temps de réponse moyen de votre programme de compression en fonction de la taille du fichier de texte ? Quel est le temps de réponse moyen de votre
programme de décompression en fonction de la taille du fichier comprimé ? \textbf{Les temps calcul observés sont-ils cohérents avec la complexité temporelle des algorithmes de compression/décompression ? Argumentez.} \\

Oui le taux de compression dépend de la taille du fichier, mais aussi de la fréquence à laquelle certain caractère reviennent. En effet pour chaque fichier compresser il y aura un "header" au fichier compresser avec l'arbre de Huffman sous forme binaire. Si le fichier est relativement petit, ce mode d'emploi va déjà prendre une certaine place, voir même plus que le fichier original. Par contre, si un fichier est très imposant, ce "header" sera insignifiant par rapport à la taille du fichier compressé.

De plus un fichier contient des caractères avec beaucoup d'occurrences, plus l'arbre de Huffman sera petit et plus les nouvelles représentations en bit des caractères seront petites. La compression sera donc beaucoup plus efficace.

\subsection*{Question 10}
L'algorithme de compression par un codage de Huffman est normalement sans perte, c’est-à-dire que le fichier compressé contient toute l'information issue du fichier original. Une fois décompressé ce fichier doit donc être strictement identique à l'original. Votre implémentation garantit-elle cette propriété ? Pourquoi ? Quels sont les tests que vous avez effectués expérimentalement à ce propos ? \\

\section{Analyse de la complexité calculatoire}
\subsection{Complexité temporelle}

\section{Répartition du travail}

\begin{itemize}
\item Rédaction du rapport : Jonathan, Sundeep
\item Conception du programme : Boris, Tanguy, Alexandre, Mathieu
\end{itemize}

\section{Difficultés rencontrées}



\end{document}
